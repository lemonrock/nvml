// This file is part of nvml. It is subject to the license terms in the COPYRIGHT file found in the top-level directory of this distribution and at https://raw.githubusercontent.com/lemonrock/nvml/master/COPYRIGHT. No part of predicator, including this file, may be copied, modified, propagated, or distributed except according to the terms contained in the COPYRIGHT file.
// Copyright Â© 2017 The developers of nvml. See the COPYRIGHT file in the top-level directory of this distribution and at https://raw.githubusercontent.com/lemonrock/nvml/master/COPYRIGHT.


// Option: https://github.com/nahratzah/ll
	// <https://nahratzah.wordpress.com/2012/10/11/lock-free-programming-and-formal-proofs/>
	// Code is close to impenetrable but could be converted... just.

// Investigate: http://drops.dagstuhl.de/opus/volltexte/2016/6678/pdf/LIPIcs-OPODIS-2015-35.pdf
	// Non-Blocking Doubly-Linked Lists with Good Amortized Complexity
	// ? https://github.com/mynameisfiber/jackslinks ?
	// ? https://github.com/Kronuz/Xapiand/commit/e26274777cab99971250fd0ffd736996bff51f6c ?

// Lesser Option: Michael Scott (https://www.cs.rochester.edu/~scott/#personal) has a C++ deque. Need to find how to get the source.

// PicoTM Blog: http://transactionblog.org/2017/12/15/porting-picotm-to-mac-os-windows-and-freebsd/
	- useful ideas


// NOTE: A skiplist (priority queue) from Facebook in C++: https://github.com/facebook/folly/blob/master/folly/ConcurrentSkipList.h

// Non-Option: ccqueue - uses a dummy node
// Non-Option : Dmitry Vjukov'q MPSC: https://groups.google.com/forum/#!topic/lock-free/Vd9xuHrLggE
// Non-Option: Moody Camel C++ queue: https://github.com/cameron314/concurrentqueue
	// http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++
	// http://moodycamel.com/blog/2014/detailed-design-of-a-lock-free-queue
// Probably Non-Option `wfqueue` (bounded array) (https://github.com/chaoran/fast-wait-free-queue)
// Probably Non-Option `lcrq` (bounded array) (https://github.com/chaoran/fast-wait-free-queue)
// Non-Option MSQueue in https://www.liblfds.org/ (uses a dummy node so won't work for us)
// Non-Option: Anything ring based


//Other

// WOW: Lock free persistent queues: http://concurrencyfreaks.blogspot.fr/2018/01/optimization-to-michael-scott.html

// WOW: https://github.com/ezrosent/wf_hash_writeup - A wait-free hashtable for Rust

// WOW: Intel TSX hashtable: 4 (5 incl an inferior original) different hopscotch hash implementations: https://www.cs.tau.ac.il/~multi/2015a/chhm.htm
	// IN C++ and Java
	// There is a hardware transactional variant with fallback
	// Code is written by students...

// WOW: https://dl.acm.org/citation.cfm?id=3079519 - a wait-free hashtable in C++. Now where is the code for it?..

// Interesting information on Bw-Trees, a Rust lock-free skip-list, etc: https://internals.rust-lang.org/t/crossbeam-request-for-help/4933/22

// TSX: Poor quality implementation, single linked list C++, HTM / libitm single linked list: https://github.com/nmldiegues/proteustm/blob/master/benchmarks/datastructures-gcc/linkedlist/linkedlist.cpp (walks the list)

// TSX: Poor quality implementation, skip list, but Intel TSX based skiplist / leaplist: https://www.cs.tau.ac.il/~multi/2015a/Leaplist.htm

// TSX: Poor quality implementation, hash map, https://github.com/nmldiegues/proteustm/blob/master/benchmarks/datastructures-gcc/hashmap/hashmap.cpp

// Contains pointers to algos that could work with Intel TSX but not adapated as such: https://software.intel.com/en-us/blogs/2013/06/23/tsx-fallback-paths

// ProteusTM (HTM / STM composite): https://github.com/nmldiegues/proteustm/

// Synquake TSM:   https://github.com/mikedw/synquake_tsx ('HythTM')


// Modern C++ implementation of a hashmap: https://shlomisteinberg.com/2015/09/28/designing-a-lock-free-wait-free-hash-map/
// C Implementation of cliff click's hashmap and a skiplist: https://code.google.com/archive/p/nbds/ or  https://github.com/argv0/nbds
// Concurrency kit (but not multi-writer) http://concurrencykit.org/
// Vjukok's hash map, 1024 cores, behaviours not known re MPMC
// Cambridge stuff (impractical): http://www.cl.cam.ac.uk/research/srg/netos/lock-free/

// Stacks
	// A modern, DWCAS aware lock-free stack: http://nullprogram.com/blog/2014/09/02/
	// https://dl.acm.org/citation.cfm?id=2676963
		//
// Branchless UTF-8 decoding: http://nullprogram.com/blog/2017/10/06/ and, potentially similar: http://bjoern.hoehrmann.de/utf-8/decoder/dfa/
// An efficient mutex MCS that doesn't use pthreads and is simpler (in some ways) to parking_lot: https://docs.rs/mcs/0.1.1/mcs/struct.Mutex.html
	// Needs a `Slot`, which is a thread-local handle.
	// Uses a spinlock with a queue of waiting threads
// Sequence Lock: https://crates.io/crates/seqlock which is very similar to a RCULock, but uses Copy and a sequence number (epoch number). Design looks more sane, and does not need a CtoArc.

// Bagpipe: Rust implementation of wf_queue / Yang + Crummey queue


Using HTM

Notes from Wang, libTM:-
"to  ensure  progress,  we  implement  a
 spinlock-based  software  fallback  path  for  every  RTM  trans-
 action started. TSX will speculatively attempt to elide the spin
 locks but should any transactions abort, critical sections will be
 protected by acquiring the spin locks in software. Our imple-
 mentation  supports  both  multiple  fine-grained  spin  locks  and
 one global spin lock as the software fallback path."

LibTM seems to be here: https://github.com/mikedw/synquake_tsx/tree/master/src/lib_tm  and untouched since 2014... despite the HythTM paper.
	Code of interest seems to be here: https://github.com/mikedw/synquake_tsx/blob/d9217fb85408216c8f0c39ec85ae462109fc9940/src/lib_tm/tm_scope.cc



(1) Persistent, Thread-safe Block Allocator for Messages

A message's size is known in advance. We ask the allocator for a size. The allocator rounds this up to align to a multiple of block size, and supplies the rounded up number of blocks.
Wherever possible, the allocator tries to provide blocks that are contiguous in memory. We can call these 'chains'.
In practice, a particular request for a size may be satisfied with one or more chains. The maximum number of chains is equal to the maximum number of blocks for the size (ie each chain is of one block).
Ideally, the allocator needs to supply the fewest possible chains, with each chain being as long as possible.

The allocator will be handed back all the blocks (ie all the chains) in a request all at once, and should have a free list that lets it identify 'best-fit' chains.

Some ideas:-
	- the free list could consist of 'chains', sorted from longest to shortest;
	- a particular request could try to find exactly the right length, then navigate up if it is not available, and 'split' the chain
	- this navigation is similar to range requests against a BTreeMap.





(2) Persistent, Thread-Safe Subscription Queue

	(2.1) Multi-Producer, Single Consumer

	(2.2) Multi-Producer, Multi Consumer for Shared Subscriptions


(3) Persistent Map, Thread-safe, Unsorted

	To find subscriptions

	State associated with a long-lived connection

	Etc

Notes on (2)
	- It would be nice if it was array based but it can be linked (although there's a much higher malloc cost).
	- It would be nice if it had a queue-depth.
	- It will have multiple producers.
	- Shared subscriptions would have multiple readers.
	- So we need a MP-SC queue and a MP-MC queue.
	- Possibilities:
		- Naive, array or linked list: would need a mutex per queue
			- array is easy to grow - Mutex + CtoVec
		- Bagpipe: Would need modification
			- implements YangCrummeyQueue (see code at ?https://github.com/chaoran/fast-wait-free-queue?)
			- implements FAAArrayQueue
		- DPDK: Has a MP / MC ring structure
			- would need modification
			- has the advantage of switchable for multi-consumer (shared subns) or single-consumer (regular subns)
		- https://crates.io/crates/multiqueue

Notes on (3)

	Options:-
		(a) See https://github.com/pmem/pcj/blob/master/src/main/java/lib/xpersistent/PersistentConcurrentHashMapInternal.java
			- based on libobj
		(b) evmap made persistent
			See https://docs.rs/evmap/2.0.1/evmap/struct.WriteHandle.html
			- based on HashMap
			- keys need clone (ok, use CtoArc)
			- values need a shallow copy, probably achievable using a CtoArc (hmm: https://docs.rs/evmap/2.0.1/evmap/trait.ShallowCopy.html ).
			- also supports a multi-map
			- multiple writers need a Mutex, however
			- has a natural persist point and potential recovery when the maps as swapped
		(c) Regular hashmap, made persistent, hosted in a RCU-Lock
			- Similar to (b) in that a mutex is used to protect writes
			- clone of hashmap occurs for write, which could be expensive for lots of entries
		(d) Modifided bisetmap (https://crates.io/crates/bisetmap), is thread-safe.
		(e) https://crates.io/crates/chashmap - uses a striped hashmap (stripes are per bucket), also wraps all access to the inner structure in a per-hashtable RwLock.
			- might not need the per-hashtable RwLock - might be sufficient to use an RcuLock / SeqLock (https://crates.io/crates/seqlock) which would optimise read access.
			- pub fn reserve() may be problematic, as it is used frequently.



Managing timeouts: https://github.com/GGist/pendulum-rs or DPDK.


A new coroutine library: https://crates.io/crates/may


See also: https://github.com/jfuentes/concurrent-data-structures
and libcds: https://github.com/khizmax/libcds
